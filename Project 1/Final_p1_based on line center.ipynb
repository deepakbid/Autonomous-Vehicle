{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os \n",
    "import math\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "   \n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_cout\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines,color=[[255, 5, 5], [5, 255, 5]], thickness = 20):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    positive_line = []\n",
    "    negative_line = []\n",
    "\n",
    "    #Tracer()()\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope_m = (y2 - y1) / (x2 - x1) \n",
    "            \n",
    "     #discard outliers\n",
    "        if (0.5 < slope_m < 1.0) or (-1.0 < slope_m < -0.5): \n",
    "            \n",
    "     # seperate x, y coordinates based on thier slope    \n",
    "            if slope_m > 0:\n",
    "        \n",
    "     # calculate center x, y coordinates for each line segement \n",
    "    \n",
    "                center_x = ((x2+x1)/2)    \n",
    "                center_y = ((y2+y1)/2)\n",
    "                intercept_b = y1 - slope_m * x1\n",
    "                length = math.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "                positive_line.append((slope_m,center_x,center_y,intercept_b,length))\n",
    "                \n",
    "                \n",
    "            elif slope_m < 0:\n",
    "                center_x = ((x2+x1)/2)    \n",
    "                center_y = ((y2+y1)/2)\n",
    "                intercept_b = y1 - slope_m * x1\n",
    "                length = math.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "                negative_line.append((slope_m,center_x,center_y,intercept_b,length)) \n",
    "\n",
    "    \n",
    "    # calculate the average slope and center for all line segements\n",
    "    # use length of line segements as weights. \n",
    "    \n",
    "    # right line \n",
    "    positive_line = np.array(positive_line)\n",
    "    right_line_slope = np.average(positive_line[:, 0]) \n",
    "    right_line_x1 = int(np.average(positive_line[:, 1],weights=positive_line[:, 4]))\n",
    "    right_line_y1 = int(np.average(positive_line[:, 2],weights=positive_line[:, 4]))\n",
    "    right_line_intercept = int(np.average(positive_line[:, 3],weights=positive_line[:, 4]))\n",
    "    \n",
    "    # left line \n",
    "    negative_line = np.array(negative_line)\n",
    "    left_line_slope = np.average(negative_line[:, 0]) \n",
    "    left_line_x1 = int(np.average(negative_line[:, 1],weights= negative_line[:, 4])) \n",
    "    left_line_y1 = int(np.average(negative_line[:, 2],weights= negative_line[:, 4])) \n",
    "    left_line_intercept = int(np.average(negative_line[:, 3],weights= negative_line[:, 4])) \n",
    "    \n",
    "\n",
    "    image_shape = img.shape\n",
    "    \n",
    "    # determine x snd y coordinates based on (y2-y1) = m (x2-x1) equation \n",
    "    \n",
    "    left_x2 = int((image_shape[0]-left_line_y1)/left_line_slope)+left_line_x1\n",
    "    right_x2 = int((image_shape[0]-right_line_y1)/right_line_slope)+right_line_x1\n",
    "    \n",
    "    \n",
    "    # use a fixed Y point and calculate new x coordinate \n",
    "    left_line_y1=330\n",
    "    new_left_x1 = int(left_x2 - ((image_shape[0]-left_line_y1)/left_line_slope))\n",
    "\n",
    "    right_line_y1=330\n",
    "    new_right_x1 = int(right_x2 - ((image_shape[0]-right_line_y1)/right_line_slope))\n",
    "    \n",
    "    # draw lines on the image \n",
    "    \n",
    "    cv2.line(img,  (new_left_x1, left_line_y1),(left_x2, image_shape[0]),color[0], thickness)\n",
    "    cv2.line(img,  (new_right_x1, right_line_y1),(right_x2, image_shape[0]), color[0], thickness)\n",
    "    \n",
    "    \n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "   \n",
    "    \n",
    "    #print(lines)\n",
    "   \n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    draw_lines(line_img, lines)\n",
    "    \n",
    "    return line_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=1.0, β=0.5, λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "\n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is the pipe line that processes all the images sequentially \n",
    "\n",
    "def process_image(image):\n",
    "            \n",
    "        # convert the image to grayscale\n",
    "            gray = grayscale(image)\n",
    "        \n",
    "            # Canny edge detection\n",
    "            canny_image = canny(gray, 50, 150)\n",
    "            \n",
    "            \n",
    "             # Gaussian Blur\n",
    "            gauss_image = gaussian_blur(canny_image, 5)\n",
    "            \n",
    "            \n",
    "            imshape = image.shape\n",
    "            vertices = np.array([[(0,imshape[0]),(430, 330), (520, 330), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "            \n",
    "            # masked image edges for region of interest\n",
    "            masked_image = region_of_interest(gauss_image, vertices)\n",
    "\n",
    "            rho = 1 # distance resolution in pixels of the Hough grid\n",
    "            theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "            threshold = 15     # minimum number of votes (intersections in Hough grid cell)\n",
    "            min_line_len = 40 #minimum number of pixels making up a line\n",
    "            max_line_gap = 20    # maximum gap in pixels between connectable line segments\n",
    "            line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "            \n",
    "            # plot hough lines\n",
    "\n",
    "            hough_image = hough_lines(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "            #plt.imshow(hough_image)\n",
    "            # overlay line image with original mage\n",
    "            final_image = weighted_img(hough_image, image)\n",
    "            \n",
    "            \n",
    "            #lines_edges = cv2.addWeighted(image, 0.8, hough_image, 1, 0) \n",
    "\n",
    "            return final_image\n",
    "        \n",
    "        \n",
    "        \n",
    "#def read_image_files():\n",
    "   \n",
    "def mark_lane_lines():\n",
    "    path = \"test_images/\"\n",
    "\n",
    "    # read files from a directory\n",
    "    \n",
    "    for filename in os.listdir(\"test_images/\"):\n",
    "\n",
    "        file_path=path+filename\n",
    "        image = mpimg.imread(file_path)\n",
    "        transformed_image = process_image(image) \n",
    "        out_file_name = \"test_images/\" + \"output_\"+filename\n",
    "        cv2.imwrite(out_file_name, cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "#starting point for reading images and calling pipeline functions   \n",
    "mark_lane_lines()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video Output_white.mp4\n",
      "[MoviePy] Writing video Output_white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:03<00:00, 64.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: Output_white.mp4 \n",
      "\n",
      "CPU times: user 3.39 s, sys: 721 ms, total: 4.11 s\n",
      "Wall time: 3.82 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'Output_white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)  # NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"Output_white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video Output_yellow.mp4\n",
      "[MoviePy] Writing video Output_yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:11<00:00, 58.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: Output_yellow.mp4 \n",
      "\n",
      "CPU times: user 11.3 s, sys: 2.25 s, total: 13.6 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'Output_yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pipeline Description\n",
    "\n",
    "####  Steps:\n",
    "1. Read the images from the test_image folder\n",
    "2. Gray Scale the image and apply Gaussian smoothing\n",
    "3. Specify vertices and mark the region of interest using fillPoly() function\n",
    "5. Define Hough transform parameters and run Hough transform on masked edge-detected image\n",
    "6. Extrapolate line segements and draw complete lines. \n",
    "7. Combine line image with original image.\n",
    "\n",
    "\n",
    "1. Spent majority of the time in creating draw line function. This function extrapolates the line segements to draw complete left and right lines on the lanes. \n",
    "\n",
    "2. The approach to draw the lines was based on identifying and bucketing positive and negative slopes for each line segement.\n",
    "\n",
    "3. x and y coordinates are determined based on calcuating the center of the line and then using the equation (y2-y1)+m(x2-x1) to calculate the missing coordinate. \n",
    "\n",
    "4. if the line segements are too short(calcuated based on the slope < 0.5 ) they are ignored and only line segements that fall between 0.5 to 1 are choosen to eliminate noise. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Shortcomings\n",
    "\n",
    "1. The vertices and image dimensions are hard coded in a few places.\n",
    "2. In the video, the lines do not appear to be smooth all the time. This indicates that top and bottom coordinates between frames have noise that should be further corrected. \n",
    "\n",
    "### Possible Improvements\n",
    "\n",
    "1. It may be possible to smoothen out the lines on videos by averaging the x & y coordinates from one frame to the next. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
